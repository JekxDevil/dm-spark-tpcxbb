{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adb557a-3b01-4e8b-be1d-dafc9b110432",
   "metadata": {},
   "source": [
    "# Apache Spark for complex queries\n",
    "**Data management, homework 7**\n",
    "\n",
    "In this assignment we will use [Apache Spark](https://spark.apache.org/): a popular framework for optimal distributed processing on large amount of data. \n",
    "The objective of is to use Apache Spark to translate and execute some queries of the TPCx-BB bigdata benchmark.  \n",
    "TPCx-BB or simply \"Big Bench\" is a common benchmark suite to evaluate the system performance on big data analytics and machine learning algorithms. We will focus on big data analytical queries, which are expressed in SQL. \n",
    "\n",
    "Spark is a framework available in multiple languages: Scala, Java, Python, R. In this excerice, we will use Python.\n",
    "\n",
    "## Get started\n",
    "### Jupyter Lab\n",
    "If you are not familiar with the Jupyter Lab environment, check out these resources from the official website: [example notebook](https://jupyter.org/try), [docs](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html).  \n",
    "Quick reference:\n",
    "- This is a cell. A cell can contain either Markdown text (such as this one) or code. Everything in jupyter notebook is a cell.\n",
    "    - You can double click on a text cell to edit iy using Markdown\n",
    "    - You can run a cell by either using the button \"play\" at the top bar or by using the \"shift + enter\" key combination\n",
    "    - Running a code cell executes it\n",
    "    - Running a text cell formats the text\n",
    "- Once you run a cell it stays in memory! So code will be run based on which order you execute cells, even if you execute a cell that is below another one before\n",
    "- General rule #1: try to arrange cell step-by-stop from top to bottom. If anything breaks, try to execute fevery cell from the top\n",
    "- General rule #2: if you are stuck or a cell is blocked during execution re-run the kernel from the topbar menu\n",
    "### Contents\n",
    "You can navigate through this exercise contents with the file explorer on the left.  \n",
    "The contents are \"extracted\" from the [TPCx-BB](https://www.tpc.org/tpc_documents_current_versions/current_specifications5.asp) benchmark source folder. Please refer to the link if you want to have a broader overview and/or additional information TPCx-BB. Since this exercise differs from the actual benchmark, only a subset of its content are reported here:\n",
    "- `queries/` contains 30 SQL/Spark queries, some of which are to be ported to Spark in this exercise. every query `qxx/` folder (`xx` = number) contains\n",
    "    - `engineLocalSettings.conf`: TPC related, disregard\n",
    "    - `engineLocalSettings.sql`: TPC related, disregard\n",
    "    - `explain_qxx.sql`: *query content* in \"explanatory\" format\n",
    "    - `explain_qxx.sql`: *query content* in TPC exec format\n",
    "    - `run.sh`: TPC related, disregard\n",
    "    - `results/qxx-result`: contains the expect result in plain-text. You should compare this with your query output (example provided later)\n",
    "- `spark_table_schemas`: contains schema information for every table in the dataset. Not relevant for the imlpementation\n",
    "- `TPCx-BB-dataset`: contains all the tables in separate folder. Refer to it for table names\n",
    "\n",
    "**Do not modify** `spark_table_schemas` or `TPCx-BB-dataset` contents as it may compromise your solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd85411-edcb-47ad-b706-ec7579aa7bf5",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "Things to mention:\n",
    "\n",
    "- using spark sql module https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "- refer to dataframe API reference: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html\n",
    "- install JupyterLab\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9dd9be8b-98c4-4b0b-aeeb-34c11b7f0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Homework 07\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d555d417-51bb-4d91-a7a0-5013581ef199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(name):\n",
    "    df = spark.read.parquet(f\"TPCx-BB-dataset/{name}.ptxt\")\n",
    "    \n",
    "    f = open(f\"spark_table_schemas/{name}.schema\",\"r\")\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        l = line.split()\n",
    "        if len(l) > 2:\n",
    "            df.schema[l[0]].nullable = False\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "251c2dd5-4548-4e7b-9fec-30c559590acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = get_table(\"customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c673e93-8be4-493b-974c-dc75aa7533c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+------------------+------------------+-----------------+----------------------+---------------------+------------+------------+-----------+---------------------+-----------+-------------+------------+--------------------+------------+--------------------+------------------+\n",
      "|c_customer_sk|   c_customer_id|c_current_cdemo_sk|c_current_hdemo_sk|c_current_addr_sk|c_first_shipto_date_sk|c_first_sales_date_sk|c_salutation|c_first_name|c_last_name|c_preferred_cust_flag|c_birth_day|c_birth_month|c_birth_year|     c_birth_country|     c_login|     c_email_address|c_last_review_date|\n",
      "+-------------+----------------+------------------+------------------+-----------------+----------------------+---------------------+------------+------------+-----------+---------------------+-----------+-------------+------------+--------------------+------------+--------------------+------------------+\n",
      "|            0|AAAAAAAAAAAAAAAA|           1824793|              3203|             2555|                 28776|                14690|         Ms.|      Marisa| Harrington|                    N|         17|            4|        1988|UNITED ARAB EMIRATES|RRCyuY3XfE3a|Marisa.Harrington...|          gdMmGdU9|\n",
      "+-------------+----------------+------------------+------------------+-----------------+----------------------+---------------------+------------+------------+-----------+---------------------+-----------+-------------+------------+--------------------+------------+--------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer.show(1) # show the 1st row of the customer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c0de66c-e2bb-4369-a2ed-efbe483764d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|    i_category|count|\n",
      "+--------------+-----+\n",
      "|Home & Kitchen| 1975|\n",
      "|         Music|25060|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## query1\n",
    "\n",
    "s = get_table(\"store_sales\")\n",
    "i = get_table(\"item\")\n",
    "\n",
    "itemArray = s.join(i, s.ss_item_sk == i.i_item_sk) \\\n",
    "                .filter(i.i_category_id < 3) \\\n",
    "                .filter(s.ss_store_sk.isin([10, 20, 33, 40, 50])) \\\n",
    "                .groupBy(\"i_category\") \\\n",
    "                .count()\n",
    "\n",
    "\n",
    "itemArray.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "028cbc53-1875-41e2-a94e-f1fd9f81022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home & Kitchen, 1975\n",
      "Music, 25060"
     ]
    }
   ],
   "source": [
    "## check the result\n",
    "!cat queries/q00/results/q00-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47ded7-6620-41a7-a185-9020d542cdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
